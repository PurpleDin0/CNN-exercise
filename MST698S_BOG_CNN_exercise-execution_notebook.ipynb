{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MST698S_BOG_CNN_exercise-execution_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PurpleDin0/CNN-exercise/blob/master/MST698S_BOG_CNN_exercise-execution_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9jIVlByg4YiE"
      },
      "source": [
        "# **Bad Ozone Grasshoppers - CNN Exercise**\n",
        "## MST 698S - Data Science Tools And Techniques \n",
        "\n",
        "**BLUF:**  Train an image classifier to identify tanks and then evaluate the usefulness of the model.\n",
        "\n",
        "**Problem Statement:** Design an image classifier to streamline the task of identifying Denovian military vehicles in social network photos.  Specifically, construct an image classifier to identify military vehicles.\n",
        "* [X] Describe other ways that image classifiers could be used to streamline data sorting, collection, and analysis process.\n",
        "* [X] How well does the model perform? would you deploy this model?  Why or Why not?\n",
        "\n",
        "**Summary:** This notebook installs the required python libraries and operating system (OS) programs to execute a python based image classifier.  Additionally, this notebook then evaluates model performance by creating a Confusion Matrix, calculating both the Matthews Correlation Coefficient and Cohens Kappa, as well as creating a classification report.\n",
        "\n",
        "**Usage Details:** This Notebook is designed to be run in the [Google Colab environment](https://colab.research.google.com/). However, it should work in ***most*** Linux based Jupyter Notebooks or Jupyter Lab environments, as long as the appropriate versions of TensorFlow, Keras, and NumPy are installed.  The main purpose of the notebook is to install relevant python libraries, execute the code, and save the output to a cloud repository.  <font color=yellow>CAUTION: If executing this notebook on a Windows based system the user will need to install Git, TensorFlow, Keras, NumPy, and update the default file paths to match windows formatting. </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xIUL-n5N6Q3i"
      },
      "source": [
        "## Initialize the Environment \n",
        "1. Clone the github repo [located here](https://github.com/PurpleDin0/CNN-exercise).  \n",
        "```\n",
        "!git clone https://github.com/[repo_owner]/[repo].git\n",
        "```\n",
        "\n",
        "2. Download the image sets from [here](https://drive.google.com/drive/folders/12H7D5-ipY5hCv2zr-6XQEUz3sXUXS3bE?usp=sharing).  Image set can be manually downloaded by the user or by using the below code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EAx6SKzRtQ_j",
        "outputId": "27e6751c-372f-4624-91c2-c12bc867ae01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "# Navigate the working directory in colab to \"/content\" \n",
        "%cd /content/\n",
        "### 1. clone the relevant github repo\n",
        "!git clone https://github.com/PurpleDin0/CNN-exercise.git\n",
        "# Navigate to the newly created repo folder\n",
        "%cd /content/CNN-exercise\n",
        "\n",
        "### 2. Download the image sets ###\n",
        "## Import PyDrive and associated libraries. ##\n",
        "# This only needs to be done once per notebook.\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "## Download a file based on its file ID. ##\n",
        "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "# This downloads the test_set.zip file from google drive\n",
        "file_id = '1xT3cTVgLBbaSeub2bwoFflPbEBnPM8Uv'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "file_name = 'test_set.zip'\n",
        "downloaded.GetContentFile(file_name)\n",
        "\n",
        "## Unzip the file that was just downloaded ##\n",
        "# The below code also prints pretty headers and displays number of unzipped files\n",
        "# There are easier ways to do this (e.g. using the os library) but this works\n",
        "# Only line that is actually needed is \"!unzip {file_name}\"\n",
        "\n",
        "# Print the unzip start banner\n",
        "txt = \"Unzipping \" +  file_name\n",
        "print(\"\\n\", \"*\"*(26-(len(txt)//2)), txt, \"*\"*(26-(len(txt)//2)))\n",
        "\n",
        "# determine the quantity of files in the current working folder/subfolders using the ! find command\n",
        "file_qty_initial = !find -type f | wc -l\n",
        "\n",
        "#Unzip the files (this is the only required line)\n",
        "!unzip -q {file_name}\n",
        "\n",
        "# same as the ! command above but uses the get_ipython method to execute instead of bash \n",
        "# (just a different way of doung the same thing)\n",
        "file_qty_after = get_ipython().getoutput('find -type f | wc -l')\n",
        "file_qty_dif = str(int(file_qty_after[0]) - int(file_qty_initial[0]))\n",
        "\n",
        "# Print the unzip completion banner\n",
        "txt = \"Unzipped \" + file_qty_dif + \" items(s)\" \n",
        "print(\"\\n\", \"*\"*(26-(len(txt)//2)), txt, \"*\"*(26-(len(txt)//2)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'CNN-exercise'...\n",
            "remote: Enumerating objects: 27, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 27 (delta 14), reused 6 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (27/27), done.\n",
            "/content/CNN-exercise\n",
            "\n",
            " *************** Unzipping test_set.zip ***************\n",
            "\n",
            " *************** Unzipped 2872 items(s) ***************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OcdsLVLmXBpk"
      },
      "source": [
        "## Train the model\n",
        "Training will take ~30 minutes per epoch if you train on a CPU (total of 12 hours).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SxwApXH0ihdL",
        "outputId": "72d6c17a-a02a-447d-a29c-e5a93bab4e67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python3 CNN_trainer.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading...\n",
            "Using TensorFlow backend.\n",
            "2020-05-26 19:33:37.604166: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "CNN will build your convolutional neural network!\n",
            "====================================================\n",
            "Accessing image data...\n",
            "Training model...\n",
            "2020-05-26 19:33:39.438113: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-05-26 19:33:39.488288: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 19:33:39.489262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2020-05-26 19:33:39.489303: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-05-26 19:33:39.765777: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-05-26 19:33:39.892504: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-05-26 19:33:39.917930: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-05-26 19:33:40.199970: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-05-26 19:33:40.240484: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-05-26 19:33:40.766883: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-26 19:33:40.767073: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 19:33:40.768061: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 19:33:40.768887: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
            "2020-05-26 19:33:40.812430: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2300000000 Hz\n",
            "2020-05-26 19:33:40.812842: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x27c6d80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-05-26 19:33:40.812878: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-05-26 19:33:40.955383: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 19:33:40.956635: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x27c6f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-05-26 19:33:40.956675: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2020-05-26 19:33:40.957948: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 19:33:40.958758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2020-05-26 19:33:40.958818: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-05-26 19:33:40.958863: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-05-26 19:33:40.958906: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-05-26 19:33:40.958940: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-05-26 19:33:40.959001: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-05-26 19:33:40.959032: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-05-26 19:33:40.959078: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-26 19:33:40.959226: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 19:33:40.960267: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 19:33:40.961068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
            "2020-05-26 19:33:40.965862: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-05-26 19:33:47.351019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-05-26 19:33:47.351085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
            "2020-05-26 19:33:47.351106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
            "2020-05-26 19:33:47.356353: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 19:33:47.357342: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-26 19:33:47.358140: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-05-26 19:33:47.358204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14974 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "Found 574 images belonging to 2 classes.\n",
            "Found 2298 images belonging to 2 classes.\n",
            "Found 574 images belonging to 2 classes.\n",
            "Epoch 1/25\n",
            "2020-05-26 19:33:49.561840: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "2020-05-26 19:33:51.041500: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2298/2298 [==============================] - 1629s 709ms/step - loss: 0.1396 - accuracy: 0.9430 - val_loss: 0.7983 - val_accuracy: 0.8832\n",
            "Epoch 2/25\n",
            "2298/2298 [==============================] - 1662s 723ms/step - loss: 0.0365 - accuracy: 0.9871 - val_loss: 0.2019 - val_accuracy: 0.9097\n",
            "Epoch 3/25\n",
            "2298/2298 [==============================] - 1717s 747ms/step - loss: 0.0171 - accuracy: 0.9944 - val_loss: 0.9561 - val_accuracy: 0.8916\n",
            "Epoch 4/25\n",
            "2298/2298 [==============================] - 1722s 749ms/step - loss: 0.0141 - accuracy: 0.9954 - val_loss: 0.8764 - val_accuracy: 0.9149\n",
            "Epoch 5/25\n",
            "2298/2298 [==============================] - 1670s 727ms/step - loss: 0.0107 - accuracy: 0.9962 - val_loss: 0.1342 - val_accuracy: 0.9097\n",
            "Epoch 6/25\n",
            "2298/2298 [==============================] - 1638s 713ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.5296 - val_accuracy: 0.8674\n",
            "Epoch 7/25\n",
            "2298/2298 [==============================] - 1617s 704ms/step - loss: 0.0078 - accuracy: 0.9975 - val_loss: 2.6915 - val_accuracy: 0.8781\n",
            "Epoch 8/25\n",
            "2298/2298 [==============================] - 1622s 706ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.2856 - val_accuracy: 0.9096\n",
            "Epoch 9/25\n",
            "2298/2298 [==============================] - 1631s 710ms/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 3.1530e-05 - val_accuracy: 0.8971\n",
            "Epoch 10/25\n",
            "2298/2298 [==============================] - 1631s 710ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 1.1283 - val_accuracy: 0.8935\n",
            "Epoch 11/25\n",
            "2298/2298 [==============================] - 1655s 720ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 2.0075 - val_accuracy: 0.8918\n",
            "Epoch 12/25\n",
            "2298/2298 [==============================] - 1606s 699ms/step - loss: 0.0057 - accuracy: 0.9985 - val_loss: 0.5250 - val_accuracy: 0.9024\n",
            "Epoch 13/25\n",
            "2298/2298 [==============================] - 1632s 710ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 1.1162 - val_accuracy: 0.8883\n",
            "Epoch 14/25\n",
            "2298/2298 [==============================] - 1602s 697ms/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 4.2325 - val_accuracy: 0.8849\n",
            "Epoch 15/25\n",
            "2298/2298 [==============================] - 1635s 711ms/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 1.0280 - val_accuracy: 0.8902\n",
            "Epoch 16/25\n",
            "2298/2298 [==============================] - 1689s 735ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 1.1675 - val_accuracy: 0.9042\n",
            "Epoch 17/25\n",
            "2298/2298 [==============================] - 1691s 736ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 2.6878 - val_accuracy: 0.9059\n",
            "Epoch 18/25\n",
            "2298/2298 [==============================] - 1701s 740ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.4582 - val_accuracy: 0.9044\n",
            "Epoch 19/25\n",
            "2298/2298 [==============================] - 1696s 738ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.6270 - val_accuracy: 0.8609\n",
            "Epoch 20/25\n",
            "2298/2298 [==============================] - 1721s 749ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.7405 - val_accuracy: 0.8727\n",
            "Epoch 21/25\n",
            "2298/2298 [==============================] - 1696s 738ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.0030 - val_accuracy: 0.8642\n",
            "Epoch 22/25\n",
            "2298/2298 [==============================] - 1704s 741ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 3.6526 - val_accuracy: 0.8971\n",
            "Epoch 23/25\n",
            "2298/2298 [==============================] - 1697s 738ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 2.3246 - val_accuracy: 0.8967\n",
            "Epoch 24/25\n",
            "2298/2298 [==============================] - 1701s 740ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 3.4222 - val_accuracy: 0.8940\n",
            "Epoch 25/25\n",
            "2298/2298 [==============================] - 1711s 745ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0110 - val_accuracy: 0.8921\n",
            "Exporting model...\n",
            "CNN model exported as CNN_model.h5\n",
            "You are a great American!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zbCl98OWnBfW"
      },
      "source": [
        "## Run the model against the test data\n",
        "1. Load the classifier function and run it against the data that was downloaded earlier located in the test_set folder.\n",
        "\n",
        "2. Store the results in a pandas data frame for easier manipulation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F155JXinOuyu",
        "outputId": "f6ee94f9-c2da-4cd8-d641-d2d877056cdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Navigate to the code from the cloned python repo\n",
        "%cd /content/CNN-exercise\n",
        "\n",
        "# Import the classifier function code\n",
        "import classifier_function\n",
        "# Import pandas so we can store the results in a dataframe\n",
        "import pandas as pd\n",
        "\n",
        "### 1. call the classifier function against the test data using the CNN Model. ###\n",
        "test_data_path = '/content/CNN-exercise/test_set/'\n",
        "model_path = '/content/CNN-exercise/CNN_model.h5'\n",
        "out_list = classifier_function.image_classifier(test_data_path, model_path)\n",
        "\n",
        "### 2. Create a dataframe that stores the predicted value and actual value for the tank classification  ###\n",
        "# Initializes two dictionaries (actual and predicted)\n",
        "out_list_fixed = {}\n",
        "out_list_actual = {}\n",
        "\n",
        "# Step through the output list and build the predicted and actual tank classification dictionaries\n",
        "for i, key in enumerate(out_list):\n",
        "    out_list_fixed[key] = int(out_list[key][0][0]) #converts the tank predication to an integer\n",
        "    if '/not_tank/' in key:\n",
        "        out_list_actual[key] = 0\n",
        "    elif '/tank/' in key:\n",
        "        out_list_actual[key] = 1\n",
        "    else:\n",
        "      print('SOMETHING BROKE ... WHAT DID YOU DO!')\n",
        "\n",
        "# Convert the dictionaries that were created into dataframes and then join those two dataframes \n",
        "df_predicted = pd.DataFrame.from_dict(out_list_fixed, orient='index', columns=['predicted'])\n",
        "df_actual = pd.DataFrame.from_dict(out_list_actual, orient='index', columns=['actual'])\n",
        "df_results = pd.concat([df_predicted, df_actual], axis=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/CNN-exercise\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kkmccT65aWZI"
      },
      "source": [
        "## Evaluate the results from the image classifier\n",
        "Next we will check the accuracy of the image classifier using several different methods.  \n",
        "* [X] Create a confusion matrix\n",
        "* [X] Calculate the Matthews Correlation Coefficient\n",
        "* [X] Calculate the Cohen kappa score\n",
        "* [X] Create a classification report\n",
        "\n",
        "Determining all of these is simplified by using the `sklearn.metrics` library and importing the classification_report, confusion_matrix, matthews_corrcoef, cohen_kappa_score functions.\n",
        "\n",
        "```python\n",
        "from sklearn.metrics import classification_report, confusion_matrix, matthews_corrcoef, cohen_kappa_score\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nIBFctbfvK7m",
        "outputId": "5687ed5e-ec4d-428c-bf0f-1e5bd95d7e5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "# Import the required functions\n",
        "from sklearn.metrics import classification_report, confusion_matrix, matthews_corrcoef, cohen_kappa_score\n",
        "\n",
        "# Build the confusion matrix\n",
        "txt = \"Confusion Matrix\"\n",
        "print(\"\\n\", \"*\"*(26-(len(txt)//2)), txt, \"*\"*(26-(len(txt)//2)))\n",
        "matrix = confusion_matrix(df_results.actual.values.tolist(), df_results.predicted.values.tolist())\n",
        "print(\"[ TP \",  matrix[0][0], \" | FP  \", matrix[0][1], \"]\\n[ FN  \", matrix[1][0], \" | TN \", matrix[1][1], \"]\")\n",
        "print(\"\\n  N =\", matrix.sum())\n",
        "\n",
        "# Determine the matthews_corrcoef\n",
        "txt = \"Matthews Correlation Coefficient\"\n",
        "print(\"\\n\", \"*\"*(26-(len(txt)//2)), txt, \"*\"*(26-(len(txt)//2)))\n",
        "print(matthews_corrcoef(df_results.actual.values.tolist(), df_results.predicted.values.tolist()))\n",
        "\n",
        "# Determine the cohen_kappa_score\n",
        "txt = \"Cohens Kappa\"\n",
        "print(\"\\n\", \"*\"*(26-(len(txt)//2)), txt, \"*\"*(26-(len(txt)//2)))\n",
        "print(cohen_kappa_score(df_results.actual.values.tolist(), df_results.predicted.values.tolist()))\n",
        "\n",
        "# Build the classification_report\n",
        "txt = \"Classification Report\"\n",
        "print(\"\\n\", \"*\"*(26-(len(txt)//2)), txt, \"*\"*(26-(len(txt)//2)))\n",
        "print(classification_report(df_results.actual.values.tolist(), df_results.predicted.values.tolist(), target_names=['Not Tank', 'Tank'], output_dict=False))  # ADDED TARGET NAMES"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " ****************** Confusion Matrix ******************\n",
            "[ TP  162  | FP   46 ]\n",
            "[ FN   17  | TN  349 ]\n",
            "\n",
            "  N = 574\n",
            "\n",
            " ********** Matthews Correlation Coefficient **********\n",
            "0.7599663028252964\n",
            "\n",
            " ******************** Cohens Kappa ********************\n",
            "0.7551227704267508\n",
            "\n",
            " **************** Classificaion Report ****************\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Not Tank       0.91      0.78      0.84       208\n",
            "        Tank       0.88      0.95      0.92       366\n",
            "\n",
            "    accuracy                           0.89       574\n",
            "   macro avg       0.89      0.87      0.88       574\n",
            "weighted avg       0.89      0.89      0.89       574\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "A_tU_oW1oThG"
      },
      "source": [
        "## Explain the Evaluation Metrics\n",
        "- [X] **Confusion Matrix `confusion_matrix(y_true, y_pred, *args)`:**  The Confusion Matrix is a representation of the model's inference grouped by its predictions into the respective box based on if results were answered correctly of not. Box values are used to tabulate addional metrics, like Matthews Correlation Coefficient (MCC).  \n",
        "\n",
        "\n",
        "- [X] **Matthews Correlation Coefficient `matthews.corrcoef(y_true, y_pred, *args)`:**  Matthews Correlation Coefficient (MCC) measures model prediction performance as a floating point value from -1 -> +1. An MCC of 1 represents a perfect prediction, and -1 MCC would show the model predicting opposite from desired results. MCC is a favorable selection for inbalanced data sets. In this project, the test set had 208 `tank` and 366 `not tank` samples--an imbalanced dataset. \n",
        "\n",
        "\n",
        "- [X] **Cohen's Kappa Score `cohen_kappa_score(y_true, y_pred, *args)`:**\n",
        "Cohen's Kappa Score is similar to MCC as it measures the performance of a model classifiers of `n` items into mutually exclusive categories, but uses a floating point number from 0 -> 1. The Kappa score statisitc is grouped into categories:  \n",
        "\n",
        "| Stat        | Agreement              | |\n",
        "| ---:        | :---                   |---|\n",
        "|      0      | equivalent to chance   | |\n",
        "| 0.10 – 0.20 | slight agreement       | |\n",
        "| 0.21 – 0.40 | fair agreement         | |\n",
        "| 0.41 – 0.60 | moderate agreement     | |\n",
        "| 0.61 – 0.80 | substantial agreement  | |\n",
        "| 0.81 – 0.99 | near perfect agreement | |\n",
        "|     1       | perfect agreement      | |\n",
        "|             |                        | [Source](http://web2.cs.columbia.edu/~julia/courses/CS6998/Interrater_agreement.Kappa_statistic.pdf) |\n",
        "\n",
        "\n",
        "\n",
        "- [X] **Classification Report `classification_report(y_true, y_pred, *args)`:**\n",
        "The Classification  Report is a simple digest of several metrics including:\n",
        "  - precision - Measures the rate of false positives.\n",
        "  - accuracy - The measure of correct predictions over the complete dataset.\n",
        "  - recall - The ability of the classifier to find positive samples in the dataset.\n",
        "  - F-1 score - Harmonic mean of precision and recall, or the accuracy of the classifier to predict in a particular category.   \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc384hAEAUTx",
        "colab_type": "text"
      },
      "source": [
        "## Model Performance and Results Discussion\n",
        "- **Describe other ways that image classifiers could be used to streamline data sorting, collection, and analysis process:**\n",
        "  - **Sorting:**  A multi-label classifier could be used to label/tag images that may contain content of interest.  Then an image search/retrieval system could be designed that allows the analyst to view the machine applied labels.  Finally, the analyst could then validate or correct the machine applied labels when they access any of the data.  This human labeled/validated data could then be used in future training cycles.  \n",
        "  - **Collection:**  Collection assets with limited onboard storage/bandwidth could incorporate automated image classification and only record/transmit images that match those they are trained to classify.\n",
        "  - **Analysis:** Binary classifiers could be trained on multi-spectral imagery of assets that human analysts have a hard time identifying.  For example, overhead imagery of similar aircraft or vehicles.  Then this system could be accessed by an analyst when they are reviewing the image to assist them in making the correct determination of specific aircraft/vehicle type.\n",
        "\n",
        "- **How well does the model perform?:**\n",
        "  - The model performs well with moderately high MCC and Cohen's Kappa Scores.  However, the model has a fairly high false positive rate.  This and the model's low False Negative rate make it a good initial image filter to help flag images that contain *potential* tanks.  \n",
        "\n",
        "- **Would you deploy this model?:**\n",
        "  - Yes, this would be of assistance to analysts that need to review vast amounts of images for potential tanks.  However, it cannot be used to conduct targeting or automate any process of the kill chain without human involvement.\n"
      ]
    }
  ]
}